{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "637ce633",
   "metadata": {},
   "source": [
    "## 学习要点\n",
    "\n",
    "1、Matcher对象的创建和使用\n",
    "\n",
    "2、匹配模式的定义技巧"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c0651715-9c63-49a2-a9a0-0121b0058af6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 导入必要的库\n",
    "# 导入 spaCy 库\n",
    "import spacy\n",
    "# 导入 Matcher 类，用于创建自定义的匹配规则。\n",
    "from spacy.matcher import Matcher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1fd6b64b-224e-46f6-80e9-59f69c718579",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 加载英文语言模型\n",
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f672e3ee-e926-4d53-a936-c69a638d1128",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 初始化匹配器\n",
    "matcher = Matcher(nlp.vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b3c4cc7d-c9bb-4b79-b77d-99f3d232602f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 定义一个匹配模式，用于查找类似电子邮件地址的文本。LIKE_EMAIL 是 spaCy 预定义的一个标记，表示类似电子邮件地址的文本。\n",
    "pattern = [{\"LIKE_EMAIL\": True}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a4beabc7-7120-4817-817b-afb1a3f9f8df",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 将定义好的匹配模式添加到匹配器中，并将其命名为 \"EMAIL_ADDRESS\"。\n",
    "matcher.add(\"EMAIL_ADDRESS\", [pattern])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6445e31e-e1c2-4fd5-a6ba-b632cd06507a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 创建一个待处理的文本\n",
    "doc = nlp(\"This is an email address: abc@gmail.com\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9e721bf3-bc91-4ef5-b489-2e3b2bf0f5b6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 使用匹配器查找文本中的匹配项\n",
    "matches = matcher(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cc439030-4b28-42ef-9f18-0804f1cfa04d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(16571425990740197027, 6, 7)]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 打印匹配结果\n",
    "matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "627f1bf1-be0b-431a-9111-699f33986f5b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "abc@gmail.com\n"
     ]
    }
   ],
   "source": [
    "print(doc[6:7])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d171ddf9-205f-43b3-8141-952f0dc61172",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'EMAIL_ADDRESS'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 通过哈希值(matches[0][0])从词汇表中获取匹配规则的名称。\n",
    "# matches[0][0]为匹配规则的唯一标识符（ID）\n",
    "nlp.vocab[matches[0][0]].text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b2adb46e-5b67-4886-b01d-20cdeac74e59",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 读取文本文件\n",
    "with open(\"data/wiki_mlk.txt\", \"r\") as f:\n",
    "    text = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "41e44890-3afd-4cb6-bcfe-d0758f392f7f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Martin Luther King Jr. (born Michael King Jr.; January 15, 1929 – April 4, 1968) was an American Baptist minister and activist who became the most visible spokesman and leader in the American civil rights movement from 1955 until his assassination in 1968. King advanced civil rights through nonviolence and civil disobedience, inspired by his Christian beliefs and the nonviolent activism of Mahatma Gandhi. He was the son of early civil rights activist and minister Martin Luther King Sr.\\n\\nKing participated in and led marches for blacks\\' right to vote, desegregation, labor rights, and other basic civil rights.[1] King led the 1955 Montgomery bus boycott and later became the first president of the Southern Christian Leadership Conference (SCLC). As president of the SCLC, he led the unsuccessful Albany Movement in Albany, Georgia, and helped organize some of the nonviolent 1963 protests in Birmingham, Alabama. King helped organize the 1963 March on Washington, where he delivered his famous \"I Have a Dream\" speech on the steps of the Lincoln Memorial.\\n\\nThe SCLC put into practice the tactics of nonviolent protest with some success by strategically choosing the methods and places in which protests were carried out. There were several dramatic stand-offs with segregationist authorities, who sometimes turned violent.[2] Federal Bureau of Investigation (FBI) Director J. Edgar Hoover considered King a radical and made him an object of the FBI\\'s COINTELPRO from 1963, forward. FBI agents investigated him for possible communist ties, recorded his extramarital affairs and reported on them to government officials, and, in 1964, mailed King a threatening anonymous letter, which he interpreted as an attempt to make him commit suicide.[3]\\n\\nOn October 14, 1964, King won the Nobel Peace Prize for combating racial inequality through nonviolent resistance. In 1965, he helped organize two of the three Selma to Montgomery marches. In his final years, he expanded his focus to include opposition towards poverty, capitalism, and the Vietnam War.\\n\\nIn 1968, King was planning a national occupation of Washington, D.C., to be called the Poor People\\'s Campaign, when he was assassinated on April 4 in Memphis, Tennessee. His death was followed by riots in many U.S. cities. Allegations that James Earl Ray, the man convicted of killing King, had been framed or acted in concert with government agents persisted for decades after the shooting. King was posthumously awarded the Presidential Medal of Freedom in 1977 and the Congressional Gold Medal in 2003. Martin Luther King Jr. Day was established as a holiday in cities and states throughout the United States beginning in 1971; the holiday was enacted at the federal level by legislation signed by President Ronald Reagan in 1986. Hundreds of streets in the U.S. have been renamed in his honor, and the most populous county in Washington State was rededicated for him. The Martin Luther King Jr. Memorial on the National Mall in Washington, D.C., was dedicated in 2011.'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 打印文本内容\n",
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e5bdc1ab-ef2b-42bb-ab6a-faee42f1422c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 重新加载英语语言模型（这行可能是多余的，因为之前已经加载过了）\n",
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "188f3912-82d3-4200-89ef-2b52d1fd8f19",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "102\n",
      "(451313080118390996, 0, 1) Martin\n",
      "(451313080118390996, 1, 2) Luther\n",
      "(451313080118390996, 2, 3) King\n",
      "(451313080118390996, 3, 4) Jr.\n",
      "(451313080118390996, 6, 7) Michael\n",
      "(451313080118390996, 7, 8) King\n",
      "(451313080118390996, 8, 9) Jr.\n",
      "(451313080118390996, 10, 11) January\n",
      "(451313080118390996, 15, 16) April\n",
      "(451313080118390996, 23, 24) Baptist\n"
     ]
    }
   ],
   "source": [
    "# 定义一个新的matcher模式来匹配专有名词\n",
    "# 初始化匹配器\n",
    "matcher = Matcher(nlp.vocab)\n",
    "# 定义匹配模式，查找专有名词\n",
    "# \"POS\" 是 spaCy 用来表示词性标签的属性。\n",
    "# \"PROPN\" 是 spaCy 用来表示专有名词的标准词性标签。\n",
    "pattern = [{\"POS\": \"PROPN\"}]\n",
    "# \"PROPER_NOUN\" 是给这个匹配规则起的名字，这是完全自定义的。\n",
    "# 将匹配模式添加到匹配器中，命名为\"PROPER_NOUN\"\n",
    "matcher.add(\"PROPER_NOUN\", [pattern])\n",
    "# 对文本进行处理\n",
    "doc = nlp(text)\n",
    "# 使用匹配器查找文本中的匹配项\n",
    "matches = matcher(doc)\n",
    "# 打印匹配项的数量\n",
    "print(len(matches))\n",
    "# 遍历前10个匹配项，并打印匹配信息和匹配到的文本\n",
    "for match in matches[:10]:\n",
    "    # 每一行都代表一个匹配项,格式为 (哈希值, 开始索引, 结束索引) 匹配的文本\n",
    "    print(match, doc[match[1]:match[2]]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6eb17614-6260-41d5-8429-28767e1f20ae",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "175\n",
      "(451313080118390996, 0, 1) Martin\n",
      "(451313080118390996, 0, 2) Martin Luther\n",
      "(451313080118390996, 1, 2) Luther\n",
      "(451313080118390996, 0, 3) Martin Luther King\n",
      "(451313080118390996, 1, 3) Luther King\n",
      "(451313080118390996, 2, 3) King\n",
      "(451313080118390996, 0, 4) Martin Luther King Jr.\n",
      "(451313080118390996, 1, 4) Luther King Jr.\n",
      "(451313080118390996, 2, 4) King Jr.\n",
      "(451313080118390996, 3, 4) Jr.\n"
     ]
    }
   ],
   "source": [
    "# 初始化Matcher，并传入nlp的词汇表\n",
    "matcher = Matcher(nlp.vocab)\n",
    "# 定义匹配模式：一个或多个专有名词\n",
    "# {\"POS\": \"PROPN\"}:这部分和之前一样,匹配词性(POS)为专有名词(PROPN)的token\n",
    "# \"OP\": \"+\":这是新添加的部分,代表\"操作符\"(operator)。\n",
    "# \"+\" 是一个量词操作符,其含义来自正则表达式。\n",
    "# 操作符 \"+\" 的具体作用:\n",
    "# 它允许匹配模式重复一次或多次。\n",
    "# 这意味着这个规则可以匹配单个专有名词,也可以匹配连续的多个专有名词。\n",
    "pattern = [{\"POS\": \"PROPN\", \"OP\": \"+\"}]\n",
    "# 将模式添加到Matcher，并命名为\"PROPER_NOUN\"\n",
    "matcher.add(\"PROPER_NOUN\", [pattern])\n",
    "# 使用nlp处理文本，生成doc对象\n",
    "doc = nlp(text)\n",
    "# 在doc中应用Matcher，获取所有匹配结果\n",
    "matches = matcher(doc)\n",
    "# 打印匹配到的总数量\n",
    "print(len(matches))\n",
    "# 遍历前10个匹配项并打印匹配编号及对应的文本片段\n",
    "for match in matches[:10]:\n",
    "    print(match, doc[match[1]:match[2]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "49550015-8547-4486-aeb5-625137e6ab69",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "61\n",
      "(451313080118390996, 83, 88) Martin Luther King Sr.\n",
      "(451313080118390996, 469, 474) Martin Luther King Jr. Day\n",
      "(451313080118390996, 536, 541) Martin Luther King Jr. Memorial\n",
      "(451313080118390996, 0, 4) Martin Luther King Jr.\n",
      "(451313080118390996, 128, 132) Southern Christian Leadership Conference\n",
      "(451313080118390996, 247, 251) Director J. Edgar Hoover\n",
      "(451313080118390996, 6, 9) Michael King Jr.\n",
      "(451313080118390996, 325, 328) Nobel Peace Prize\n",
      "(451313080118390996, 422, 425) James Earl Ray\n",
      "(451313080118390996, 463, 466) Congressional Gold Medal\n"
     ]
    }
   ],
   "source": [
    "# 初始化匹配器\n",
    "matcher = Matcher(nlp.vocab) \n",
    "# 定义匹配模式：查找一个或多个连续的专有名词\n",
    "pattern = [{\"POS\": \"PROPN\", \"OP\": \"+\"}]  \n",
    "# 将匹配模式添加到匹配器，命名为 \"PROPER_NOUN\"，并设置为贪婪匹配最长的序列\n",
    "matcher.add(\"PROPER_NOUN\", [pattern], greedy=\"LONGEST\") \n",
    "# 使用nlp模型处理文本\n",
    "doc = nlp(text)\n",
    "# 使用匹配器查找文本中的匹配项\n",
    "matches = matcher(doc) \n",
    "# 打印匹配到的专有名词序列数量\n",
    "print(len(matches))\n",
    "\n",
    "# 遍历前10个匹配项，打印匹配信息和匹配到的文本\n",
    "for match in matches[:10]:\n",
    "    print(match, doc[match[1]:match[2]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f44c19aa-4b6c-4fcf-9f51-e289557d57b4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "61\n",
      "(451313080118390996, 0, 4) Martin Luther King Jr.\n",
      "(451313080118390996, 6, 9) Michael King Jr.\n",
      "(451313080118390996, 10, 11) January\n",
      "(451313080118390996, 15, 16) April\n",
      "(451313080118390996, 23, 24) Baptist\n",
      "(451313080118390996, 49, 50) King\n",
      "(451313080118390996, 69, 71) Mahatma Gandhi\n",
      "(451313080118390996, 83, 88) Martin Luther King Sr.\n",
      "(451313080118390996, 89, 90) King\n",
      "(451313080118390996, 113, 114) King\n"
     ]
    }
   ],
   "source": [
    "# 初始化匹配器\n",
    "matcher = Matcher(nlp.vocab) \n",
    "# 定义匹配模式：查找一个或多个连续的专有名词\n",
    "pattern = [{\"POS\": \"PROPN\", \"OP\": \"+\"}]  \n",
    "# 将匹配模式添加到匹配器，命名为 \"PROPER_NOUN\"，并设置为贪婪匹配最长的序列\n",
    "matcher.add(\"PROPER_NOUN\", [pattern], greedy=\"LONGEST\")  \n",
    "# 使用nlp模型处理文本\n",
    "doc = nlp(text)\n",
    "# 使用匹配器查找文本中的匹配项\n",
    "matches = matcher(doc) \n",
    "# 对匹配结果按照起始位置排序\n",
    "# 按照匹配项的开始位置（x[1]）对结果进行排序。\n",
    "# 结果是匹配项会按照它们在原文中出现的顺序排列，而不是按照匹配器找到它们的顺序。\n",
    "matches.sort(key=lambda x: x[1]) \n",
    "# 打印匹配到的专有名词序列数量\n",
    "print(len(matches)) \n",
    "# 遍历前10个匹配项，打印匹配信息和匹配到的文本\n",
    "for match in matches[:10]:\n",
    "    print(match, doc[match[1]:match[2]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4c69ee96-ea68-4c1c-a2cb-f8c13a95b112",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n",
      "(451313080118390996, 49, 51) King advanced\n",
      "(451313080118390996, 89, 91) King participated\n",
      "(451313080118390996, 113, 115) King led\n",
      "(451313080118390996, 167, 169) King helped\n",
      "(451313080118390996, 247, 252) Director J. Edgar Hoover considered\n",
      "(451313080118390996, 322, 324) King won\n",
      "(451313080118390996, 485, 488) United States beginning\n"
     ]
    }
   ],
   "source": [
    "# 创建一个Matcher对象，使用nlp.vocab作为词汇表\n",
    "matcher = Matcher(nlp.vocab)\n",
    "# 定义一个匹配模式，匹配一个或多个专有名词后跟一个动词\n",
    "pattern = [{\"POS\": \"PROPN\", \"OP\": \"+\"}, {\"POS\": \"VERB\"}]\n",
    "# 将模式添加到matcher对象，命名为\"PROPER_NOUN\"，使用贪婪匹配，选择最长的匹配项\n",
    "matcher.add(\"PROPER_NOUN\", [pattern], greedy=\"LONGEST\")\n",
    "# 使用nlp对象处理文本\n",
    "doc = nlp(text)\n",
    "# 使用matcher对象匹配文本\n",
    "matches = matcher(doc)\n",
    "# 对匹配结果按起始位置排序\n",
    "matches.sort(key = lambda x: x[1])\n",
    "# 打印匹配结果的数量\n",
    "print(len(matches))\n",
    "# 循环打印前10个匹配结果\n",
    "for match in matches[:10]:\n",
    "  # 打印匹配结果的id、起始位置和结束位置，以及匹配到的文本\n",
    "  print(match, doc[match[1]:match[2]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "07b5e6ab-0ec2-45e4-ae28-08b0b3689a83",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 导入json库\n",
    "import json\n",
    "# 打开名为\"data/alice.json\"的文件，以只读模式打开\n",
    "with open(\"data/alice.json\", \"r\") as f:\n",
    "    # 使用json.load()函数加载文件内容到变量data\n",
    "    data=json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6ae41c60-e648-4429-8194-61ec14f398de",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 从data中提取文本内容，赋值给变量text\n",
    "text = data[0][2][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7f10f833-9303-46ad-af16-0b4b526602a3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Alice was beginning to get very tired of sitting by her sister on the bank, and of having nothing to do: once or twice she had peeped into the book her sister was reading, but it had no pictures or conversations in it, `and what is the use of a book,' thought Alice `without pictures or conversation?'\""
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 打印text的内容\n",
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "fce77510-01a5-485f-915f-e2b6ec7fd890",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Alice was beginning to get very tired of sitting by her sister on the bank, and of having nothing to do: once or twice she had peeped into the book her sister was reading, but it had no pictures or conversations in it, 'and what is the use of a book,' thought Alice 'without pictures or conversation?'\""
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 将text中的\"`\"替换成\"'\"\n",
    "text= text.replace(\"`\", \"'\")\n",
    "\n",
    "# 打印text的内容\n",
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7c30f53a-b11b-4a0a-aa2c-5cd63511cb7b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "(451313080118390996, 47, 58) 'and what is the use of a book,'\n",
      "(451313080118390996, 60, 67) 'without pictures or conversation?'\n"
     ]
    }
   ],
   "source": [
    "# 初始化Matcher对象\n",
    "matcher = Matcher(nlp.vocab)\n",
    "# 定义匹配模式，寻找被单引号括起来的，包含至少一个字母和任意数量的标点符号的字符串\n",
    "pattern = [{\"ORTH\": \"'\"},\n",
    "           {\"IS_ALPHA\": True, \"OP\": \"+\"},\n",
    "           {\"IS_PUNCT\": True, \"OP\": \"*\"},\n",
    "           {\"ORTH\": \"'\"}\n",
    "          ]\n",
    "# 将模式命名为\"PROPER_NOUN\"，添加到matcher对象中，设置greedy为\"LONGEST\"以优先匹配最长的字符串\n",
    "matcher.add(\"PROPER_NOUN\", [pattern], greedy=\"LONGEST\")\n",
    "# 使用nlp对象处理文本text\n",
    "doc = nlp(text)\n",
    "# 使用matcher对象匹配doc中的文本\n",
    "matches = matcher(doc)\n",
    "# 对匹配结果按照起始位置排序\n",
    "matches.sort(key = lambda x: x[1])\n",
    "# 打印匹配结果的数量\n",
    "print(len(matches))\n",
    "# 打印前10个匹配结果，包括匹配的span和对应的文本\n",
    "for match in matches[:10]:\n",
    "    print(match, doc[match[1]:match[2]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8e138bed-5341-4dec-8c05-4d45065d8306",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "(451313080118390996, 47, 67) 'and what is the use of a book,' thought Alice 'without pictures or conversation?'\n"
     ]
    }
   ],
   "source": [
    "# 定义speak_lemmas列表，包含\"think\"和\"say\"\n",
    "speak_lemmas = [\"think\", \"say\"]\n",
    "# 初始化Matcher对象\n",
    "matcher = Matcher(nlp.vocab)\n",
    "# 定义匹配模式，寻找被单引号括起来的字符串，后面跟着speak_lemmas中的动词，然后是一个或多个专有名词，再后面是被单引号括起来的字符串\n",
    "pattern = [{\"ORTH\": \"'\"},\n",
    "           {\"IS_ALPHA\": True, \"OP\": \"+\"},\n",
    "           {\"IS_PUNCT\": True, \"OP\": \"*\"},\n",
    "           {\"ORTH\": \"'\"},\n",
    "           {\"POS\": \"VERB\", \"LEMMA\": {\"IN\": speak_lemmas}},\n",
    "           {\"POS\": \"PROPN\", \"OP\": \"+\"},\n",
    "           {\"ORTH\": \"'\"},\n",
    "           {\"IS_ALPHA\": True, \"OP\": \"+\"},\n",
    "           {\"IS_PUNCT\": True, \"OP\": \"*\"},\n",
    "           {\"ORTH\": \"'\"}\n",
    "          ]\n",
    "# 将模式命名为\"PROPER_NOUN\"，添加到matcher对象中，设置greedy为\"LONGEST\"以优先匹配最长的字符串\n",
    "matcher.add(\"PROPER_NOUN\", [pattern], greedy=\"LONGEST\")\n",
    "# 使用nlp对象处理文本text\n",
    "doc = nlp(text)\n",
    "# 使用matcher对象匹配doc中的文本\n",
    "matches = matcher(doc)\n",
    "# 对匹配结果按照起始位置排序\n",
    "matches.sort(key = lambda x: x[1])\n",
    "# 打印匹配结果的数量\n",
    "print(len(matches))\n",
    "# 打印前10个匹配结果，包括匹配的span和对应的文本\n",
    "for match in matches[:10]:\n",
    "    print(match, doc[match[1]:match[2]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7742f08b-f64b-48a0-b1fc-14fdcb5be067",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "(451313080118390996, 47, 67) 'and what is the use of a book,' thought Alice 'without pictures or conversation?'\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "# 遍历data[0][2]中的每个文本\n",
    "for text in data[0][2]:\n",
    "    # 将文本中的\"`\"替换成\"'\"\n",
    "    text = text.replace(\"`\", \"'\")\n",
    "    # 使用nlp对象处理文本\n",
    "    doc = nlp(text)\n",
    "    # 使用matcher对象匹配文本\n",
    "    matches = matcher(doc)\n",
    "    # 打印匹配结果的数量\n",
    "    print(len(matches))\n",
    "    # 对匹配结果按照起始位置排序\n",
    "    matches.sort(key = lambda x: x[1])\n",
    "    # 打印前10个匹配结果，包括匹配的span和对应的文本\n",
    "    for match in matches[:10]:\n",
    "        print(match, doc[match[1]:match[2]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9d09184b-a19e-4242-9c23-f2ac491a9566",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "(3232560085755078826, 47, 67) 'and what is the use of a book,' thought Alice 'without pictures or conversation?'\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "(3232560085755078826, 0, 6) 'Well!' thought Alice\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "(3232560085755078826, 57, 68) 'which certainly was not here before,' said Alice\n",
      "0\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "# 只需满足其中一个 pattern 就算匹配成功\n",
    "# 定义speak_lemmas列表，包含\"think\"和\"say\"\n",
    "speak_lemmas = [\"think\", \"say\"]\n",
    "# 从data中提取文本内容，赋值给变量text，并将\"`\"替换成\"'\"\n",
    "text = data[0][2][0].replace( \"`\", \"'\")\n",
    "# 初始化Matcher对象\n",
    "matcher = Matcher(nlp.vocab)\n",
    "# 定义匹配模式1，寻找被单引号括起来的字符串，后面跟着speak_lemmas中的动词，然后是一个或多个专有名词，再后面是被单引号括起来的字符串\n",
    "pattern1 = [{'ORTH': \"'\"}, {'IS_ALPHA': True, \"OP\": \"+\"}, {'IS_PUNCT': True, \"OP\": \"*\"}, {'ORTH': \"'\"}, {\"POS\": \"VERB\", \"LEMMA\": {\"IN\": speak_lemmas}}, {\"POS\": \"PROPN\", \"OP\": \"+\"}, {'ORTH': \"'\"}, {'IS_ALPHA': True, \"OP\": \"+\"}, {'IS_PUNCT': True, \"OP\": \"*\"}, {'ORTH': \"'\"}]\n",
    "# 定义匹配模式2，寻找被单引号括起来的字符串，后面跟着speak_lemmas中的动词，然后是一个或多个专有名词\n",
    "pattern2 = [{'ORTH': \"'\"}, {'IS_ALPHA': True, \"OP\": \"+\"}, {'IS_PUNCT': True, \"OP\": \"*\"}, {'ORTH': \"'\"}, {\"POS\": \"VERB\", \"LEMMA\": {\"IN\": speak_lemmas}}, {\"POS\": \"PROPN\", \"OP\": \"+\"}]\n",
    "# 定义匹配模式3，寻找一个或多个专有名词，后面跟着speak_lemmas中的动词，再后面是被单引号括起来的字符串\n",
    "pattern3 = [{\"POS\": \"PROPN\", \"OP\": \"+\"},{\"POS\": \"VERB\", \"LEMMA\": {\"IN\": speak_lemmas}}, {'ORTH': \"'\"}, {'IS_ALPHA': True, \"OP\": \"+\"}, {'IS_PUNCT': True, \"OP\": \"*\"}, {'ORTH': \"'\"}]\n",
    "# 将模式命名为\"PROPER_NOUNS\"，并将三个模式添加到matcher对象中，设置greedy为\"LONGEST\"以优先匹配最长的字符串\n",
    "matcher.add(\"PROPER_NOUNS\", [pattern1, pattern2, pattern3], greedy='LONGEST')\n",
    "# 遍历data[0][2]中的每个文本\n",
    "for text in data[0][2]:\n",
    "    # 将文本中的\"`\"替换成\"'\"\n",
    "    text = text.replace(\"`\", \"'\")\n",
    "    # 使用nlp对象处理文本\n",
    "    doc = nlp(text)\n",
    "    # 使用matcher对象匹配文本\n",
    "    matches = matcher(doc)\n",
    "    # 对匹配结果按照起始位置排序\n",
    "    matches.sort(key = lambda x: x[1])\n",
    "    # 打印匹配结果的数量\n",
    "    print (len(matches))\n",
    "    # 打印前10个匹配结果，包括匹配的span和对应的文本\n",
    "    for match in matches[:10]:\n",
    "        print (match, doc[match[1]:match[2]])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (spacy-tutorial)",
   "language": "python",
   "name": "spacy-tutorial"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
